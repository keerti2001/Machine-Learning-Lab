{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> CS353 Machine Learning Lab</h1>\n",
    "<h1 align='center'>Multilinear Regression (02/03/21)</h1>\n",
    "<h2 align='center'>Keerti Chaudhary 181Co226</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task:\n",
    "Perform naive bayes classification on breast cancer standard dataset.\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "1. X1: Login Hours\n",
    "\n",
    "2. X2 : Break time duration\n",
    "\n",
    "3. Y : Productivity **(Label)**\n",
    "\n",
    "\n",
    "**Results:**\n",
    "\n",
    "Score Obtained:\n",
    "    - 0.8744986822452062\n",
    "\n",
    "Intercept:  \n",
    "    - 5.670821261340636 \n",
    "\n",
    "Coefficients:  \n",
    "    - [0.41691176, 0.0181036]\n",
    "   \n",
    "   \n",
    "**Errors**\n",
    "\n",
    " Mean-sq-error            : 0.005314693361129525\n",
    "\n",
    " Mean-abs-error           : 0.05699019027630511\n",
    "\n",
    " R2-score                 : 0.9319985211115073\n",
    "\n",
    " Mean-sq-log-error        : 5.3247855209029075e-05\n",
    "\n",
    " *Explained-variance-score* : \\\n",
    "     0.952883347729859"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>9.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.3</td>\n",
       "      <td>1.38</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>8.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.9</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.2</td>\n",
       "      <td>1.67</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.5</td>\n",
       "      <td>1.08</td>\n",
       "      <td>9.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.4</td>\n",
       "      <td>1.22</td>\n",
       "      <td>9.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.2</td>\n",
       "      <td>1.37</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.1</td>\n",
       "      <td>1.25</td>\n",
       "      <td>9.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.6</td>\n",
       "      <td>1.40</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.8</td>\n",
       "      <td>1.27</td>\n",
       "      <td>8.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.9</td>\n",
       "      <td>1.63</td>\n",
       "      <td>8.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1    X2     Y\n",
       "0   8.1  1.25  9.03\n",
       "1   7.3  1.38  8.65\n",
       "2   7.8  1.57  8.94\n",
       "3   8.9  1.27  9.42\n",
       "4   9.2  1.67  9.58\n",
       "5   8.5  1.08  9.19\n",
       "6   8.4  1.22  9.17\n",
       "7   7.2  1.37  8.99\n",
       "8   9.1  1.25  9.57\n",
       "9   7.6  1.40  8.80\n",
       "10  7.8  1.27  8.88\n",
       "11  7.9  1.63  8.90"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "temp={\"X1\":[8.1,7.3,7.8,8.9,9.2,8.5,8.4,7.2,9.1,7.6,7.8,7.9], \n",
    "      \"X2\":[1.25,1.38,1.57,1.27,1.67,1.08,1.22,1.37,1.25,1.40,1.27,1.63], \n",
    "      \"Y\":[9.03,8.65,8.94,9.42,9.58,9.19,9.17,8.99,9.57,8.80,8.88,8.90]}\n",
    "df=pd.DataFrame(temp)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.1</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.3</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.9</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.2</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1    X2\n",
       "0  8.1  1.25\n",
       "1  7.3  1.38\n",
       "2  7.8  1.57\n",
       "3  8.9  1.27\n",
       "4  9.2  1.67"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_multi = df.drop(\"Y\", axis=1)\n",
    "X_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9.03\n",
       "1    8.65\n",
       "2    8.94\n",
       "3    9.42\n",
       "4    9.58\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi = df[\"Y\"]\n",
    "y_multi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Multilinear regression model\n",
    "\n",
    "\n",
    "Multiple linear regression (MLR), also known simply as multiple regression, is a statistical technique that uses several explanatory variables to predict the outcome of a response variable. Multiple regression is an extension of linear (OLS) regression that uses just one explanatory variable. It is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables. \n",
    "\n",
    "1. Using \"sklearn\" standard library\n",
    "2. Using \"statsmodels.api\" standard library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using \"sklearn\" library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm3 = linear_model.LinearRegression()\n",
    "lm3.fit(X_multi, y_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LinearRegression in module sklearn.linear_model._base object:\n",
      "\n",
      "class LinearRegression(sklearn.base.MultiOutputMixin, sklearn.base.RegressorMixin, LinearModel)\n",
      " |  LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  LinearRegression fits a linear model with coefficients w = (w1, ..., wp)\n",
      " |  to minimize the residual sum of squares between the observed targets in\n",
      " |  the dataset, and the targets predicted by the linear approximation.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : bool, optional, default True\n",
      " |      Whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (i.e. data is expected to be centered).\n",
      " |  \n",
      " |  normalize : bool, optional, default False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\n",
      " |      an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : bool, optional, default True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup for n_targets > 1 and sufficient large problems.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array of shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  rank_ : int\n",
      " |      Rank of matrix `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  singular_ : array of shape (min(X, y),)\n",
      " |      Singular values of `X`. Only available when `X` is dense.\n",
      " |  \n",
      " |  intercept_ : float or array of shape of (n_targets,)\n",
      " |      Independent term in the linear model. Set to 0.0 if\n",
      " |      `fit_intercept = False`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.linear_model.Ridge : Ridge regression addresses some of the\n",
      " |      problems of Ordinary Least Squares by imposing a penalty on the\n",
      " |      size of the coefficients with l2 regularization.\n",
      " |  sklearn.linear_model.Lasso : The Lasso is a linear model that estimates\n",
      " |      sparse coefficients with l1 regularization.\n",
      " |  sklearn.linear_model.ElasticNet : Elastic-Net is a linear regression\n",
      " |      model trained with both l1 and l2 -norm regularization of the\n",
      " |      coefficients.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_\n",
      " |  3.0000...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      LinearModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training data\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MultiOutputMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix or a list of generic objects instead,\n",
      " |          shape = (n_samples, n_samples_fitted),\n",
      " |          where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with :func:`~sklearn.metrics.r2_score`. This will influence the\n",
      " |      ``score`` method of all the multioutput regressors (except for\n",
      " |      :class:`~sklearn.multioutput.MultiOutputRegressor`). To specify the\n",
      " |      default value manually and avoid the warning, please either call\n",
      " |      :func:`~sklearn.metrics.r2_score` directly or make a custom scorer with\n",
      " |      :func:`~sklearn.metrics.make_scorer` (the built-in scorer ``'r2'`` uses\n",
      " |      ``multioutput='uniform_average'``).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  5.670821261340636 \n",
      "Coefficients:  [0.41691176 0.0181036 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Intercept: \",lm3.intercept_ , \"\\nCoefficients: \", lm3.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.8744986822452062\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: \",lm3.score(X_multi, y_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using \"statsmodels.api\" library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const   X1    X2\n",
       "0    1.0  8.1  1.25\n",
       "1    1.0  7.3  1.38\n",
       "2    1.0  7.8  1.57\n",
       "3    1.0  8.9  1.27\n",
       "4    1.0  9.2  1.67"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_multi_cons = sn.add_constant(X_multi)\n",
    "X_multi_cons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting OLS(Ordinary Least Square) and printing summary of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shumbul/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1535: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=12\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 27 Feb 2021</td> <th>  Prob (F-statistic):</th> <td>8.79e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:14:39</td>     <th>  Log-Likelihood:    </th> <td>  10.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    12</td>      <th>  AIC:               </th> <td>  -14.79</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     9</td>      <th>  BIC:               </th> <td>  -13.34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    5.6708</td> <td>    0.532</td> <td>   10.657</td> <td> 0.000</td> <td>    4.467</td> <td>    6.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>    0.4169</td> <td>    0.053</td> <td>    7.888</td> <td> 0.000</td> <td>    0.297</td> <td>    0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>    0.0181</td> <td>    0.199</td> <td>    0.091</td> <td> 0.929</td> <td>   -0.431</td> <td>    0.467</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.446</td> <th>  Durbin-Watson:     </th> <td>   1.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  11.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.855</td> <th>  Prob(JB):          </th> <td> 0.00400</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.885</td> <th>  Cond. No.          </th> <td>    135.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.874\n",
       "Model:                            OLS   Adj. R-squared:                  0.847\n",
       "Method:                 Least Squares   F-statistic:                     31.36\n",
       "Date:                Sat, 27 Feb 2021   Prob (F-statistic):           8.79e-05\n",
       "Time:                        11:14:39   Log-Likelihood:                 10.397\n",
       "No. Observations:                  12   AIC:                            -14.79\n",
       "Df Residuals:                       9   BIC:                            -13.34\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          5.6708      0.532     10.657      0.000       4.467       6.875\n",
       "X1             0.4169      0.053      7.888      0.000       0.297       0.536\n",
       "X2             0.0181      0.199      0.091      0.929      -0.431       0.467\n",
       "==============================================================================\n",
       "Omnibus:                       16.446   Durbin-Watson:                   1.493\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               11.044\n",
       "Skew:                           1.855   Prob(JB):                      0.00400\n",
       "Kurtosis:                       5.885   Cond. No.                         135.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_multi = sn.OLS(y_multi, X_multi_cons).fit()\n",
    "lm_multi.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that the intercept and the coefficients are the same as we got using \"sklearn\" library.** \\\n",
    "Thus, both the methods give the same values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test & split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_multi,y_multi,test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2) (3, 2) (9,) (3,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_a = linear_model.LinearRegression()\n",
    "lm_a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.19480381, 9.02128343, 9.55511667])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_a = lm_a.predict(X_test)\n",
    "y_test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.95353715, 8.97596399, 9.48288502, 8.75758995, 8.71600831,\n",
       "       8.8815873 , 9.40271199, 9.07454426, 9.22517203])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_a = lm_a.predict(X_train)\n",
    "y_train_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from sklearn.metrics import mean_squared_log_error,explained_variance_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lm_a.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Metrics for model evualtion:\n",
      "\n",
      "\n",
      " Mean-sq-error            : 0.005314693361129525\n",
      "\n",
      " Mean-abs-error           : 0.05699019027630511\n",
      "\n",
      " R2-score                 : 0.9319985211115073\n",
      "\n",
      " Mean-sq-log-error        : 5.3247855209029075e-05\n",
      "\n",
      " Explained-variance-score : 0.952883347729859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\nMetrics for model evualtion:\\n\\n')\n",
    "\n",
    "mean_sq_error = mean_squared_error(y_test,prediction)\n",
    "mean_abs_error = mean_absolute_error(y_test,prediction)\n",
    "R2_score = metrics.r2_score(y_test,prediction)\n",
    "mean_sq_log_error = mean_squared_log_error(y_test,prediction)\n",
    "explained_variance_score = metrics.explained_variance_score( y_test,prediction, multioutput='uniform_average')\n",
    "\n",
    "print(f' Mean-sq-error            : {mean_sq_error}\\n\\n Mean-abs-error           : {mean_abs_error}\\n\\n R2-score                 : {R2_score}\\n\\n Mean-sq-log-error        : {mean_sq_log_error}\\n\\n Explained-variance-score : {explained_variance_score}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
